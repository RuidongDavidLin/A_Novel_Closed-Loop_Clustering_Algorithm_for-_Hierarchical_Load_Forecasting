{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ee0dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"20\"  # ← 改成你的物理核数\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from utils2 import *\n",
    "\n",
    "np.random.seed(47)\n",
    "\n",
    "# Parameter\n",
    "\n",
    "train_ratio = 0.72\n",
    "val_ratio   = 0.18\n",
    "\n",
    "# 加载原始数据 \n",
    "load_data   = np.load('user_load.npz')\n",
    "PV_data     = np.load('PV_data.npz')\n",
    "Radiation   = np.load('Radiation.npz')\n",
    "\n",
    "load_data   = load_data['data']\n",
    "PV_data     = PV_data['PV']\n",
    "Radiation   = Radiation['Radiation'][:365*48]\n",
    "num_user    = 400\n",
    "# 保证Prosumer数据不会出现负数\n",
    "load_data  += 1\n",
    "\n",
    "# 放缩光伏功率数据\n",
    "x_min = np.min(PV_data, axis=1, keepdims=True)  # 每行最小值\n",
    "x_max = np.max(PV_data, axis=1, keepdims=True)  # 每行最大值\n",
    "PV_data = 1.05 * (PV_data - x_min) / (x_max - x_min)\n",
    "\n",
    "# 处理Prosumer和Consumer数据\n",
    "user_list = np.arange(num_user)\n",
    "site_list = np.arange(int(len(user_list)*0.1))\n",
    "prosumer_list = np.random.choice(user_list, size=int(len(user_list)*0.1), replace=False)\n",
    "consumer_list = np.setdiff1d(user_list, prosumer_list)\n",
    "\n",
    "load_data   = load_data[user_list]\n",
    "PV_data     = PV_data[site_list][:,:365*48]\n",
    "load_data[prosumer_list] -= PV_data\n",
    "load_data = np.clip(load_data, 0, None)\n",
    "\n",
    "\n",
    "\n",
    "# 生成时间序列（从 2010-01-01 开始）\n",
    "date_rng = pd.date_range('2010-01-01', periods=365*24, freq='60min')\n",
    "\n",
    "# 提取 weekday（0=Mon, 6=Sun）\n",
    "weekday = date_rng.weekday.values  # shape: (17520,)\n",
    "\n",
    "# One-hot 编码 (7 类)\n",
    "weekday_onehot = np.eye(7)[weekday]  # shape: (17520, 7)\n",
    "\n",
    "# 去掉一列以消除共线性（例如去掉 Sunday 列）\n",
    "weekday_onehot = weekday_onehot[:, 1:]  # shape: (17520, 6)\n",
    "\n",
    "# 计算每个时间步对应的小时数\n",
    "# 0, 0.5, 1.0, ... , 23.5, 然后循环\n",
    "hours = np.arange(365*24) % 24\n",
    "\n",
    "# 生成正弦/余弦特征（24小时周期）\n",
    "hour_sin = np.sin(2 * np.pi * hours / 24).reshape(-1,1)\n",
    "hour_cos = np.cos(2 * np.pi * hours / 24).reshape(-1,1)\n",
    "\n",
    "Calendar = np.concatenate((weekday_onehot, hour_sin), axis=1)\n",
    "Calendar = np.concatenate((Calendar, hour_cos), axis=1)\n",
    "\n",
    "load_data = load_data.reshape(num_user, 2,-1).sum(axis=1)\n",
    "Radiation = Radiation.reshape(2,-1).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f337a741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最小MAE聚类数 1 最小MAE 61.120310577180895\n",
      "最小MAPE聚类数 1 最小MAPE 4.233868116247346\n"
     ]
    }
   ],
   "source": [
    "# K-Means\n",
    "MAE_list = []\n",
    "MAPE_list = []\n",
    "# 5\n",
    "for K in range(9,10):\n",
    "    save_path   = \"Process_3\\\\K-means\\\\\"\n",
    "    os.makedirs(save_path,exist_ok=True)\n",
    "\n",
    "    kmeans      = KMeans(n_clusters=K,random_state=49,n_init='auto')\n",
    "    k_data      = load_data[:,:int(load_data.shape[1]*train_ratio)]\n",
    "\n",
    "    kmeans.fit(k_data)\n",
    "    cluster_list = np.array(kmeans.labels_)\n",
    "    aggr_data = aggregate_by_cluster_list(load=load_data,labels=cluster_list,num_cluster=K, agg='sum')\n",
    "    model_dict = train_model(cluster_num=K, cluster_list=cluster_list, aggr_data=aggr_data, \n",
    "                                    lag=24,train_ratio=train_ratio, Radiation=Radiation,Calendar=Calendar)\n",
    "\n",
    "    predict_result, test_result = Predict(cluster_num=K,cluster_list=cluster_list,\n",
    "                                        aggr_data=aggr_data,lag=24,train_ratio=train_ratio,\n",
    "                                        val_ratio=val_ratio,Radiation=Radiation,\n",
    "                                        Calendar=Calendar,model_dict=model_dict)\n",
    "\n",
    "    predict_result = predict_result.sum(axis=0)\n",
    "    test_result = test_result.sum(axis=0)\n",
    "\n",
    "    np.save(save_path+\"predict_result.npy\",predict_result)\n",
    "    np.save(save_path+\"test_result.npy\",test_result)\n",
    "    \n",
    "    MAE  = np.mean(np.abs(predict_result-test_result))\n",
    "    MAPE = np.mean(np.abs(predict_result-test_result)/test_result)*100\n",
    "    \n",
    "    MAE_list.append(MAE)\n",
    "    MAPE_list.append(MAPE)\n",
    "MAPE_list = np.asarray(MAPE_list)\n",
    "MAE_list = np.asarray(MAE_list)\n",
    "\n",
    "print(\"最小MAE聚类数\",np.argmin(MAE_list)+1,\"最小MAE\",np.min(MAE_list))\n",
    "print(\"最小MAPE聚类数\",np.argmin(MAPE_list)+1,\"最小MAPE\",np.min(MAPE_list))\n",
    "\n",
    "# np.save(save_path+\"predict_result.npy\",predict_result)\n",
    "# np.save(save_path+\"test_result.npy\",test_result)\n",
    "\n",
    "# 最小MAE聚类数 5 最小MAE 126.30187904876584\n",
    "# 最小MAPE聚类数 5 最小MAPE 0.7250700345199731"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfd50202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 FINISHED\n",
      "最小MAE聚类数 1 最小MAE 61.20740653965068\n",
      "最小MAPE聚类数 1 最小MAPE 4.238647920917969\n"
     ]
    }
   ],
   "source": [
    "# GMM\n",
    "# K = 10\n",
    "save_path   = \"Process_3\\\\GMM\\\\\"\n",
    "os.makedirs(save_path,exist_ok=True)\n",
    "\n",
    "MAE_list = []\n",
    "MAPE_list = []\n",
    "# 3\n",
    "for K in range(14,15):\n",
    "    gmm = GaussianMixture(n_components=K, covariance_type=\"diag\", n_init=3, random_state=49)\n",
    "    gmm.fit(load_data[:,:int(load_data.shape[1]*train_ratio)])\n",
    "    cluster_list = np.array(gmm.predict(load_data[:,:int(load_data.shape[1]*train_ratio)]))\n",
    "\n",
    "    aggr_data = aggregate_by_cluster_list(load=load_data,labels=cluster_list,num_cluster=K, agg='sum')\n",
    "    model_dict = train_model(cluster_num=K, cluster_list=cluster_list, aggr_data=aggr_data, \n",
    "                                    lag=24,train_ratio=train_ratio, Radiation=Radiation,Calendar=Calendar)\n",
    "\n",
    "    predict_result, test_result = Predict(cluster_num=K,cluster_list=cluster_list,\n",
    "                                        aggr_data=aggr_data,lag=24,train_ratio=train_ratio,\n",
    "                                        val_ratio=val_ratio,Radiation=Radiation,\n",
    "                                        Calendar=Calendar,model_dict=model_dict)\n",
    "\n",
    "    predict_result = predict_result.sum(axis=0)\n",
    "    test_result = test_result.sum(axis=0)\n",
    "\n",
    "    np.save(save_path+\"predict_result.npy\",predict_result)\n",
    "    np.save(save_path+\"test_result.npy\",test_result)\n",
    "\n",
    "    MAE  = np.mean(np.abs(predict_result-test_result))\n",
    "    MAPE = np.mean(np.abs(predict_result-test_result)/test_result)*100\n",
    "\n",
    "    MAE_list.append(MAE)\n",
    "    MAPE_list.append(MAPE)\n",
    "    print(\"Epoch:\",K,\"FINISHED\")\n",
    "\n",
    "MAPE_list = np.asarray(MAPE_list)\n",
    "MAE_list = np.asarray(MAE_list)\n",
    "\n",
    "print(\"最小MAE聚类数\",np.argmin(MAE_list)+1,\"最小MAE\",np.min(MAE_list))\n",
    "print(\"最小MAPE聚类数\",np.argmin(MAPE_list)+1,\"最小MAPE\",np.min(MAPE_list))\n",
    "\n",
    "# np.save(save_path+\"predict_result.npy\",predict_result)\n",
    "# np.save(save_path+\"test_result.npy\",test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26fe8f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Up_to_down\n",
    "K = 1\n",
    "save_path   = \"Process_3\\\\Up_to_down\\\\\"\n",
    "os.makedirs(save_path,exist_ok=True)\n",
    "\n",
    "kmeans      = KMeans(n_clusters=K,random_state=49,n_init='auto')\n",
    "k_data      = load_data[:,:int(load_data.shape[1]*train_ratio)]\n",
    "\n",
    "kmeans.fit(k_data)\n",
    "cluster_list = np.array(kmeans.labels_)\n",
    "aggr_data = aggregate_by_cluster_list(load=load_data,labels=cluster_list,num_cluster=K, agg='sum')\n",
    "model_dict = train_model(cluster_num=K, cluster_list=cluster_list, aggr_data=aggr_data, \n",
    "                                lag=24,train_ratio=train_ratio, Radiation=Radiation,Calendar=Calendar)\n",
    "\n",
    "predict_result, test_result = Predict(cluster_num=K,cluster_list=cluster_list,\n",
    "                                    aggr_data=aggr_data,lag=24,train_ratio=train_ratio,\n",
    "                                    val_ratio=val_ratio,Radiation=Radiation,\n",
    "                                    Calendar=Calendar,model_dict=model_dict)\n",
    "\n",
    "# predict_result = predict_result.sum(axis=0)\n",
    "# test_result = test_result.sum(axis=0)\n",
    "\n",
    "np.save(save_path+\"predict_result.npy\",predict_result)\n",
    "np.save(save_path+\"test_result.npy\",test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a64a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bottom_to_Up\n",
    "K = num_user\n",
    "save_path   = \"Process_3\\\\Bottom_to_Up\\\\\"\n",
    "os.makedirs(save_path,exist_ok=True)\n",
    "\n",
    "kmeans      = KMeans(n_clusters=K,random_state=49,n_init='auto')\n",
    "k_data      = load_data[:,:int(load_data.shape[1]*train_ratio)]\n",
    "\n",
    "kmeans.fit(k_data)\n",
    "cluster_list = np.array(kmeans.labels_)\n",
    "aggr_data = aggregate_by_cluster_list(load=load_data,labels=cluster_list,num_cluster=K, agg='sum')\n",
    "model_dict = train_model(cluster_num=K, cluster_list=cluster_list, aggr_data=aggr_data, \n",
    "                                lag=24,train_ratio=train_ratio, Radiation=Radiation,Calendar=Calendar)\n",
    "\n",
    "predict_result, test_result = Predict(cluster_num=K,cluster_list=cluster_list,\n",
    "                                    aggr_data=aggr_data,lag=24,train_ratio=train_ratio,\n",
    "                                    val_ratio=val_ratio,Radiation=Radiation,\n",
    "                                    Calendar=Calendar,model_dict=model_dict)\n",
    "\n",
    "predict_result = predict_result.sum(axis=0)\n",
    "test_result = test_result.sum(axis=0)\n",
    "\n",
    "np.save(save_path+\"predict_result.npy\",predict_result)\n",
    "np.save(save_path+\"test_result.npy\",test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d6ba2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble\n",
    "save_path   = \"Process_3\\\\Ensemble\\\\\"\n",
    "os.makedirs(save_path,exist_ok=True)\n",
    "\n",
    "predict_val_total = []\n",
    "test_val_total = []\n",
    "predict_result_total = []\n",
    "test_result_total = []\n",
    "for K in [i for i in range(1,20)]:\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=K,random_state=49,n_init='auto')\n",
    "    kmeans.fit(load_data[:,:int(load_data.shape[1]*train_ratio)])\n",
    "    cluster_list = np.array(kmeans.labels_)\n",
    "    aggr_data = aggregate_by_cluster_list(load=load_data,labels=cluster_list,num_cluster=K, agg='sum')\n",
    "    model_dict = train_model(cluster_num=K, cluster_list=cluster_list, aggr_data=aggr_data, \n",
    "                            lag=24,train_ratio=train_ratio, Radiation=Radiation,Calendar=Calendar)\n",
    "    predict_val, test_val = Predict_val(cluster_num=K,cluster_list=cluster_list,\n",
    "                                        aggr_data=aggr_data,lag=24,train_ratio=train_ratio,\n",
    "                                        val_ratio=val_ratio,Radiation=Radiation,\n",
    "                                        Calendar=Calendar,model_dict=model_dict)\n",
    "    \n",
    "    predict_val_total.append(predict_val.sum(axis=0))\n",
    "    test_val_total.append(test_val.sum(axis=0))\n",
    "    \n",
    "    predict_result, test_result = Predict(cluster_num=K,cluster_list=cluster_list,\n",
    "                                        aggr_data=aggr_data,lag=24,train_ratio=train_ratio,\n",
    "                                        val_ratio=val_ratio,Radiation=Radiation,\n",
    "                                        Calendar=Calendar,model_dict=model_dict)\n",
    "    predict_result_total.append(predict_result.sum(axis=0))\n",
    "    test_result_total.append(test_result.sum(axis=0))\n",
    "\n",
    "predict_val_total = np.asarray(predict_val_total).T\n",
    "test_val_total = np.asarray(test_val_total).mean(axis=0).T\n",
    "\n",
    "Combinator = LinearRegression().fit(X=predict_val_total,y=test_val_total)\n",
    "predict_result_total = Combinator.predict(np.asarray(predict_result_total).T)\n",
    "\n",
    "np.save(save_path+\"predict_result.npy\",np.asarray(predict_result_total))\n",
    "np.save(save_path+\"test_result.npy\",np.asarray(test_result_total).mean(axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HLF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
